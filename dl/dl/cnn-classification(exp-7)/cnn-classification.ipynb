{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjHNZVeu2MjT"
      },
      "outputs": [],
      "source": [
        "# Dataset - https://www.kaggle.com/datasets/salader/dogs-vs-cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdI1xtHv6c_H"
      },
      "outputs": [],
      "source": [
        "# To speed up training go to Runtime select Change Runtime type to GPU or TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QghlOcT4D3HH"
      },
      "outputs": [],
      "source": [
        "# go to your Kaggle profile and create a new token download from kaggle and upload to current working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAKFsvSH2dMV"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhrgXdC83Ftf",
        "outputId": "d07274dd-087c-47a1-feb3-f3d82fef76f9"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d salader/dogs-vs-cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywFIphxL3oQh"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/dogs-vs-cats.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ-MJmI335bI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization,Dropout #BN and DO are used to increase accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMRR5bLj4_5u",
        "outputId": "494c7f53-4669-4807-f215-51e0864fcd00"
      },
      "outputs": [],
      "source": [
        "# generators divides the data into batches to increase the speed and use RAM effectively\n",
        "# gererators are very useful to process large amount of data\n",
        "# detailed documentation of generators https://keras.io/api/data_loading/image/\n",
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/train',#path of Train folder\n",
        "    labels='inferred',\n",
        "    label_mode = 'int',#assign 0 for cat and 1 for dog\n",
        "    batch_size=32,\n",
        "    image_size=(256,256)#reshape images to 256*256*3\n",
        ")\n",
        "\n",
        "validation_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/test',#path of Test folder\n",
        "    labels='inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size=32,\n",
        "    image_size=(256,256)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyYbNeZJ5O-v"
      },
      "outputs": [],
      "source": [
        "# Normalize to values from 0-255 to 0-1\n",
        "def process(image,label):\n",
        "    image = tf.cast(image/255. ,tf.float32)\n",
        "    return image,label\n",
        "\n",
        "train_ds = train_ds.map(process)\n",
        "validation_ds = validation_ds.map(process)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dQCQhG65z0X"
      },
      "outputs": [],
      "source": [
        "# create CNN model\n",
        "# CNN Architecture - 3 Convolutional Layers - in first layer 32 filters - in second layer 64 filters - and in third layer 128 filters\n",
        "# Pooling layer for Dimensionality Reduction & Translation Invariance\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3zI8up1530X",
        "outputId": "3f132291-ec4f-4b9c-8132-a56eeec3c094"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOq3kN7_56DP"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4SNvWT45-FT",
        "outputId": "8ab23a9c-bac9-4cfa-afc5-3cd3d88ff295"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_ds,epochs=10,validation_data=validation_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "2Uln_BtdDTzn",
        "outputId": "dfe35032-c746-48a4-9039-3b0140597943"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'],color='red',label='train')\n",
        "plt.plot(history.history['val_accuracy'],color='blue',label='validation')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "#try to decrease the gap to reduce overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "2rg_9OuADgrl",
        "outputId": "f6104cda-1a53-4d04-fc94-0748f41db111"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'],color='red',label='train')\n",
        "plt.plot(history.history['val_loss'],color='blue',label='validation')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "#try to decrease the gap to reduce overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4_rKVeqApBI"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4AbSyYAAuoS"
      },
      "outputs": [],
      "source": [
        "test_img1 = cv2.imread('/content/Dog.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "t07nUbnnA7Aq",
        "outputId": "088028b1-38b5-4c1f-b940-c9a3cb3ff99d"
      },
      "outputs": [],
      "source": [
        "plt.imshow(test_img1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VhDvUDuA9YJ",
        "outputId": "8c42b672-7352-4053-f3e5-fb25427c4525"
      },
      "outputs": [],
      "source": [
        "test_img1.shape #actual shape of the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bxastv4aA_fO"
      },
      "outputs": [],
      "source": [
        "test_img1 = cv2.resize(test_img1,(256,256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZDxLknTBBae"
      },
      "outputs": [],
      "source": [
        "test_input1 = test_img1.reshape((1,256,256,3)) #in this batch there is only one image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y49n2TcVBD1B",
        "outputId": "ceda7e62-c604-4562-c034-e9345d993a69"
      },
      "outputs": [],
      "source": [
        "model.predict(test_input1) # classn 0 for Cat and 1 for Dog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZnkur3JBwDk"
      },
      "outputs": [],
      "source": [
        "test_img2 = cv2.imread('/content/Cat.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "CluAuWlrB2xP",
        "outputId": "16e6f656-dbce-46fa-8d45-85bc50d9bec6"
      },
      "outputs": [],
      "source": [
        "plt.imshow(test_img2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPmVi3x7B7RG",
        "outputId": "b0dd2708-44a8-450d-ef3c-03b6516c29b5"
      },
      "outputs": [],
      "source": [
        "test_img2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sno7E2mqCABc"
      },
      "outputs": [],
      "source": [
        "test_img2 = cv2.resize(test_img2,(256,256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRd3_5VXCPv0"
      },
      "outputs": [],
      "source": [
        "test_input2 = test_img2.reshape((1,256,256,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zI8ijCp2CUIW",
        "outputId": "36b43166-21c0-4060-dbd3-3209a27d5970"
      },
      "outputs": [],
      "source": [
        "model.predict(test_input2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
